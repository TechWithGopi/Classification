{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a pro level overview of classification report with a table, real world example, and formulas:\n",
    "\n",
    "What is a classification report?\n",
    "\n",
    "A classification report is a performance evaluation metric in machine learning that is used to show the precision, recall, F1 score, and support of your trained classification model. It is a table that shows these metrics for each class in your dataset.\n",
    "\n",
    "Precision\n",
    "\n",
    "Precision is the percentage of correct positive predictions relative to the total number of positive predictions. For example, if a model predicts that 100 emails are spam, and 90 of those emails are actually spam, then the precision is 90%.\n",
    "\n",
    "Recall\n",
    "\n",
    "Recall is the percentage of correct positive predictions relative to the total number of actual positives. For example, if there are actually 100 spam emails in a dataset, and the model correctly predicts 90 of them, then the recall is 90%.\n",
    "\n",
    "F1 score\n",
    "\n",
    "The F1 score is a weighted harmonic mean of precision and recall. It is a measure of how well the model balances both precision and recall. The F1 score can be calculated as follows:\n",
    "\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "Support\n",
    "\n",
    "Support is the number of actual occurrences of the class in the specified dataset. For example, if there are 100 spam emails in a dataset, then the support for the spam class is 100.\n",
    "\n",
    "Table of classification report metrics\n",
    "\n",
    "The following table shows the classification report metrics for a hypothetical model that predicts whether an email is spam or not.\n",
    "\n",
    "Class\tPrecision\tRecall\tF1 score\tSupport\n",
    "Spam\t  90%\t      90%\t  90%\t     100\n",
    "Not spam  95%\t      95%\t  95%\t     100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Real world example\n",
    "\n",
    "Let's say you are building a model to predict whether a customer will churn. You could use a classification report to evaluate the performance of your model. The classification report would show you the precision, recall, and F1 score for each class (churn and not churn). This would help you to understand how well your model is predicting churn and not churn customers.\n",
    "\n",
    "Formulas\n",
    "\n",
    "The following are the formulas for precision, recall, and F1 score:\n",
    "\n",
    "Precision = True Positives / (True Positives + False Positives)\n",
    "Recall = True Positives / (True Positives + False Negatives)\n",
    "F1 = 2 * (Precision * Recall) / (Precision + Recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
